import axios from "axios";
import { envs } from "@/config/envs";

const OLLAMA_URL = "http://localhost:11434";

// Cliente Axios con configuraciÃ³n base
const ollama = axios.create({
  baseURL: OLLAMA_URL,
  headers: {
    "Content-Type": "application/json",
  },
  timeout: 30000,
});

async function setupOllama() {
  const modelName = envs.TEXT_EMBEDDING_MODEL_NAME;

  try {
    console.log("ğŸ” Verificando si Ollama responde en el puerto 11434...");

    // Verificar conexiÃ³n
    await ollama.get("/api/tags");
    console.log("âœ… Ollama estÃ¡ accesible");

    console.log(`ğŸ“¥ Verificando modelo ${modelName}...`);

    // Obtener lista de modelos
    const { data: tags } = await ollama.get("/api/tags");

    const exists = tags.models.some((m: any) => m.name === modelName);

    if (!exists) {
      console.log(`â¬‡ï¸  Modelo ${modelName} no encontrado. Descargando...`);

      // API /api/pull
      await ollama.post("/api/pull", { name: modelName });

      console.log("âœ… Modelo descargado correctamente");
    } else {
      console.log("âœ… Modelo ya estÃ¡ instalado");
    }

  } catch (err: any) {
    console.error(`
âŒ No se pudo conectar a Ollama en http://localhost:11434

Detalles: ${err.message}

Por favor verifica:

- Â¿El contenedor "ollama" estÃ¡ corriendo?
- Â¿El puerto 11434 estÃ¡ expuesto?
- Â¿Tu contenedor "app" usa network_mode: host?
- Â¿Podes acceder desde el host con "curl localhost:11434/api/tags"?

`);
    process.exit(1);
  }
}

setupOllama();
